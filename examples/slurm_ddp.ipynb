{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c443b989-5a71-455f-9a59-9963338634ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (c) Meta Platforms, Inc. and affiliates. Confidential and proprietary.\n",
    "\n",
    "# @noautodeps\n",
    "# pyre-ignore-all-errors\n",
    "import logging\n",
    "import os\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from monarch.actor import Actor, current_rank, endpoint\n",
    "from monarch.job import SlurmJob\n",
    "from monarch.utils import setup_env_for_distributed\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(name)s %(asctime)s %(levelname)s %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    force=True,\n",
    ")\n",
    "\n",
    "\n",
    "logger: logging.Logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class ToyModel(nn.Module):\n",
    "    \"\"\"A simple toy model for demonstration purposes.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ToyModel, self).__init__()\n",
    "        self.net1 = nn.Linear(10, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.net2 = nn.Linear(10, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net2(self.relu(self.net1(x)))\n",
    "\n",
    "\n",
    "class DDPActor(Actor):\n",
    "    \"\"\"This Actor wraps the basic functionality from Torch's DDP example.\n",
    "\n",
    "    Conveniently, all of the methods we need are already laid out for us,\n",
    "    so we can just wrap them in the usual Actor endpoint semantic with some\n",
    "    light modifications.\n",
    "\n",
    "    Adapted from: https://docs.pytorch.org/tutorials/intermediate/ddp_tutorial.html#basic-use-case\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.rank = current_rank().rank\n",
    "\n",
    "    def _rprint(self, msg):\n",
    "        \"\"\"Helper method to print with rank information.\"\"\"\n",
    "        print(f\"{self.rank=} {msg}\")\n",
    "\n",
    "    @endpoint\n",
    "    async def setup(self):\n",
    "        \"\"\"Initialize the PyTorch distributed process group.\"\"\"\n",
    "        self._rprint(\"Initializing torch distributed\")\n",
    "\n",
    "        WORLD_SIZE = int(os.environ[\"WORLD_SIZE\"])\n",
    "        # initialize the process group\n",
    "        dist.init_process_group(\"gloo\", rank=self.rank, world_size=WORLD_SIZE)\n",
    "        self._rprint(\"Finished initializing torch distributed\")\n",
    "\n",
    "    @endpoint\n",
    "    async def cleanup(self):\n",
    "        \"\"\"Clean up the PyTorch distributed process group.\"\"\"\n",
    "        self._rprint(\"Cleaning up torch distributed\")\n",
    "        dist.destroy_process_group()\n",
    "\n",
    "    @endpoint\n",
    "    async def demo_basic(self):\n",
    "        \"\"\"Run a basic DDP training example.\"\"\"\n",
    "        self._rprint(\"Running basic DDP example\")\n",
    "\n",
    "        # create model and move it to GPU with id rank\n",
    "        local_rank = int(os.environ[\"LOCAL_RANK\"])\n",
    "        self._rprint(f\"{local_rank=}\")\n",
    "        model = ToyModel().to(local_rank)\n",
    "        ddp_model = DDP(model, device_ids=[local_rank])\n",
    "\n",
    "        loss_fn = nn.MSELoss()\n",
    "        optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = ddp_model(torch.randn(20, 10))\n",
    "        labels = torch.randn(20, 5).to(local_rank)\n",
    "        loss_fn(outputs, labels).backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"{self.rank=} Finished running basic DDP example\")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    num_nodes = 2\n",
    "    gpus_per_node = 8\n",
    "    mesh_name = \"mesh0\"\n",
    "    \n",
    "    # Create SLURM job\n",
    "    slurm_job = SlurmJob(\n",
    "        meshes={mesh_name: num_nodes},\n",
    "        job_name=\"monarch_example\",\n",
    "        gpus_per_node=gpus_per_node,\n",
    "        time_limit=\"06:00:00\",\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Get job state and create process mesh\n",
    "        job_state = slurm_job.state()\n",
    "        proc_mesh = job_state.mesh0.spawn_procs({\"gpus\": gpus_per_node})\n",
    "\n",
    "        # Spawn DDP actor\n",
    "        ddp_actor = proc_mesh.spawn(\"ddp_actor\", DDPActor)\n",
    "\n",
    "        # Setup distributed environment\n",
    "        await setup_env_for_distributed(proc_mesh)\n",
    "\n",
    "        # Run DDP example\n",
    "        await ddp_actor.setup.call()\n",
    "        await ddp_actor.demo_basic.call()\n",
    "        await ddp_actor.cleanup.call()\n",
    "\n",
    "        print(\"DDP example completed successfully!\")\n",
    "\n",
    "    finally:\n",
    "        # Cancel the SLURM job, releasing all reserved nodes back to the cluster\n",
    "        slurm_job.kill()\n",
    "        logger.info(\"Job terminated successfully\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7fcfc7-3561-43bd-9945-278fb488e0ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (monarch)",
   "language": "python",
   "name": "monarch"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
